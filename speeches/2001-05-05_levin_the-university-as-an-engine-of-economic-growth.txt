 I am pleased and greatly honored to be with you today, and I am especially grateful for the warm welcome that I have been given by President Wang Dazhong and his colleagues. Tsinghua University is well known in the United States as one of China’s most distinguished centers of learning. Many members of our faculty at Yale have close personal and professional relationships with scholars and scientists here, and we are eager to expand those relationships. It is my hope that collaboration between our two institutions will continue to flourish.
I thought that I would speak to you today about a topic that reflects both my work as an economist and my experience as a university president. It is a topic that holds, I believe, many lessons for a great university such as Tsinghua, which through its strong programs in science and engineering contributes so profoundly to the dynamic economic development of China. My title is “The University as an Engine of Economic Growth.”
Introduction
My point is a simple one: universities can be an essential source of national economic competitiveness and, ultimately, a wellspring of worldwide growth and prosperity.
To persuade you of the truth of this point, I would like to develop a two-fold argument. First, I want to illustrate that the way research is funded and organized in the United States makes our universities the nation’s principal source of new scientific discovery, and hence, ultimately, the principal source of technological advance and economic innovation. Second, I will claim that the spirit of critical inquiry and the pedagogical methods that prevail in leading American universities and colleges are also powerful engines of creative leadership, in industry and commerce as well as in science and technology.
The Contribution of University Research to Economic Growth
A dozen years ago, when U.S. trade deficits first reached the level of $100 billion annually and many were questioning the long-term competitive viability of the nation’s industries, I offered a seminar for Yale College seniors entitled “The International Competitiveness of U.S. Manufacturing.” I asked each student to choose a particular industry and make a report to the class on all the available indicators of the competitive status of U.S. firms in world markets: sales, employment, productivity growth, market share, exports, imports, and patents obtained, among others. The students were required to collect data for the United States, Germany, and Japan over a time span extending from 1960 to the mid-1980s.
The results were very revealing. The data the students collected indicated that the alleged decline in U.S. global competitiveness was largely concentrated in a handful of industrial sectors. In essence, we had suffered an enormous absolute and comparative decline in the performance of two industries that were the nation’s largest employers in the 1960s, automobiles and steel. But in most other sectors of manufacturing, we were holding our own, and in those sectors with technologies most closely linked to recent advances in scientific knowledge - pharmaceuticals, specialty chemicals, and segments of the electronics industry - America led the world.
Competitive advantage based on the innovative application of new scientific knowledge - this has been the key to American economic success for at least the past quarter century. And the pattern is no different today. America remains the world’s leader in the industries where science-based technologies are changing rapidly - software, communications equipment, and biotechnology. As technologies mature, labor cost, quality control, and other factors become more important in determining competitive success, and the United States tends to lose its comparative advantage. The dynamic sectors of the American economy - where new jobs are created and productivity growth is most rapid - remain those that create innovative new products based on the application of recent scientific knowledge.
As the nation’s principal locus of basic scientific research, our universities play a key role in this pattern of economic competitiveness and growth. Basic research, by definition, is motivated purely by curiosity and the quest for knowledge. It has no clear, practical, commercial objective. Yet basic research is the source from which all commercially oriented applied research and development ultimately flows. I say ultimately because it often takes decades before the commercial implications of an important scientific discovery are fully realized. The commercial potential of a particular discovery is often unanticipated, and often extends to many, economically unrelated industries and applications. In other words, the development of innovative, commercial products that occurs today depends on advances in basic research achieved ten, twenty, or fifty years ago - most often without any idea of the eventual consequences.
In 1998, U.S. academic institutions spent an estimated $26 billion on research, nearly 70 percent of which that was spent on basic research. Over the past three decades, academic institutions have accounted for approximately half of the total basic research undertaken in the United States.
The universities’ role as America’s primary basic research machine did not come about by accident. A half-century ago, in the aftermath of World War II and as the Cold War was beginning, the U.S. government clearly and self-consciously established an unprecedented and heavily subsidized system of support of scientific research, in the process transforming the nature and scope of the American university. This system has three central features, all of which remain largely intact today. First, the federal government shoulders the principal responsibility for the financial support of basic scientific research. Second, universities - rather than government laboratories, non-teaching research institutes, or private industry - are the primary institutions in which this government-funded research is undertaken. And third, although the Federal budgetary process determines the total amount available to support research in the various fields of science, most funds are allocated, not according to commercial or political considerations, but through an intensely competitive process of review conducted by independent scientific experts who judge the quality of proposals according to their scientific merit alone. Within constraints set by the overall budget, there is a virtual free market in ideas.
This system of organizing science has been, on its own terms and from an international comparative perspective, an extraordinary success. Over the past three decades, the U.S. has been the source of about 35% of all scientific publications worldwide, and more than 60% of the world’s Nobel prizes have been awarded to Americans or to foreign nationals working in American universities. It is also clear that publicly funded basic science has been critical to scientific and technological innovation. A recent study prepared for the National Science Foundation found that 73% of the main science papers cited in industrial patents granted in the U.S. were based on research financed by government or nonprofit agencies and carried out in large part in university laboratories.
It is unlikely that this success could be duplicated by industry. The private sector has little incentive to invest in basic research because the returns from the creation of new generic knowledge are difficult to appropriate for private benefit. In contrast, it is much easier to reap the returns from investment in applied research directed toward a specific commercial end, especially if the legal framework governing intellectual property provides effective protection against the imitation of one’s products by rivals.
Moreover, the time lags between the initiation of basic (or even long-term applied) research and commercial application are long, far longer than an impatient private sector could tolerate. Scientists cannot schedule fundamental breakthroughs, and the eventual applications that arise from them may be surprises, both in form and in timing. Ordinarily, the ultimate commercial applications are entirely unforeseen when the initial, enabling discoveries are made in university laboratories. It has been forty-eight years since Watson and Crick discovered the double helix, and the enormous practical benefits of this discovery are only now beginning to be realized through new medical treatments and a whole new technology for developing pharmaceuticals. Universities, in their unending, unadulterated search to know, are uniquely situated to undertake such long-term research without worrying about its commercial application and payoff - a luxury that profit-seeking private industrial firms cannot afford.
Examples of how university-based research has yielded enormous and unanticipated benefits are abundant. Take the laser. In the 1950s, Professor William Bennett began working on the phenomenon of coherent light. After he came to Yale in 1961, he continued his work on lasers with the support of grants from the U.S. Department of Defense. For many years, the laser was what Professor Bennett calls “a solution looking for a problem.” Today there are so many uses for lasers that it would be impossible to describe them all in the time that remains. Lasers are used to cut cloth, to lay out the foundations of a house, to make microchips, to pinpoint and treat brain tumors without surgery. In fact, when Professor Bennett suffered from a detached retina in 1995, the treatment he received was accomplished by using precisely the same Argon Ion Laser that he developed at Yale in 1964.
Today, in our research universities, there are hundreds if not thousands of currently active long-term projects with great economic potential. Everyone knows about the enormous opportunities made possible by mapping the human genome, but there are many other examples. To highlight just one, researchers at Yale and Rice University have achieved initial success in building individual molecules that serve the same function as transistors and other components in microcircuits. If successful this technique could lead to ultra-fast, ultra-small computer processors.
Aside from stimulating scientific discoveries and advances, the deliberate decision to locate most fundamental research in universities rather than government laboratories or private research institutes had another equally significant benefit. It enabled the next generation of scientists to receive its education and training from the nation’s best scientists, who are required to teach as they pursue their own research. I cannot overemphasize how conducive this model of graduate education is to the creativity of the students and also to the vitality of the research enterprise.
Of course, some of these well-trained graduate students become professors after they complete their degrees and post-doctoral study, thus ensuring that the academic research engine is continually replenished with new, skilled scientists. But the many who enter industrial employment after graduation take with them invaluable assets - state-of-the-art knowledge obtained by working at the frontiers of science and experience with the most advanced research tools and equipment. They also take with them a particular way of thinking, a topic to which I turn next.
The Contribution of Liberal Education to Economic Growth
The knowledge created by the enterprise of academic science is by no means the only contribution of American universities to economic growth. By engaging students in intellectual inquiry, encouraging them to question received wisdom, developing their capacity to think independently, and fostering their problem-solving abilities, universities and colleges contribute to economic growth through their teaching as well as their research. And it is not only the education of industrial scientists and engineers that has an impact on economic performance, it is the education of all those engaged in the business sector - executives, entrepreneurs, financiers, and consultants alike.
The world we live in is fast-paced and constantly changing. Many successful companies produce products or services based on technology or marketing strategies that didn’t exist a decade or two ago. In such a world, knowledge of a given body of information is not enough to survive, much less thrive; students who aspire to leadership in business or government must have the ability to think critically and creatively, and to draw upon and adapt ideas to new environments.
The methods of undergraduate, as well as much professional, education used by America’s most selective and distinguished universities and liberal arts colleges are particularly well suited to prepare students for a changing world. Unlike British universities, which require students to specialize early, America’s finest research universities and liberal arts colleges are committed to the “liberal education” of undergraduates. Liberal education cultivates the intellect and expands the capacity to reason and to empathize. Its object is not to convey any particular content, but to develop certain qualities of mind: to sift through information to extract what is useful, to transcend prejudice and superstition, to think critically and independently. Just as the largest social benefits derive from scientific research that is driven by a wide-ranging curiosity rather than a particular commercial objective, so, I would argue, the largest social benefits derive from a pedagogy that enlarges the power of students to reason and think creatively rather than master a specific body of knowledge.
What does this mean in practical terms? It means that, at America’s best universities and colleges, education is not a one-way street. Information is no longer simply conveyed from faculty to students. Even as recently as the 1930s and 40s, in many college classes, professors spewed forth information in lectures, students copiously took notes, memorized them, and then “recited” them back to the professor when called upon in class. Today, students can not rely on a good memory to succeed in college. Although lectures are still used in many courses, students are no longer encouraged to recite back what they hear in class or read in a textbook. Instead, students are encouraged to think for themselves - to offer their own opinions and interpretations in classes, writing assignments, and examinations.
The participatory seminar is now a fundamental part of most undergraduate and graduate programs at America’s top universities and liberal arts colleges. The purpose of small seminars is to challenge students to articulate their views and defend them in the face of classmates and the professor, who may disagree. The format forces them to reason through issues and to think critically for themselves, not just repeat what a professor has told them or what they have read. Often, these seminars are accompanied by in-depth research and writing assignments, where students are required to engage in independent study and write a paper articulating and defending their own conclusions.
Even most lecture classes for undergraduates have some form of discussion section attached to them, to give students the opportunity to discuss for themselves the materials presented in lecture. Like the participatory seminar, these discussion sections consist of relatively small numbers of students, and they emphasize exchanging views and developing analytical skills, not memorization and recitation.
Professors also encourage critical thinking by the form of writing assignments they require and by the kind of examination questions they ask. In the mid-1980s, while he was the President of Harvard, Derek Bok studied the examinations given there in various subjects since 1900. He found that, at the beginning of the century, nearly all of exam questions “sought to have students repeat particular facts, describe the opinions of others, or relate fixed sequences of events. … The emphasis was chiefly on memory.”1
As the century progressed, the nature of exams changed in a way that increasingly “emphasized analysis rather than memory or description.” By 1960, according to Bok, “half of the questions in the humanities and social sciences called upon students to discuss complex problems from more than one perspective.”2 
As Bok’s survey shows, students today are expected to take from their courses not just facts, figures, and widely accepted theories, but a way of thinking - the ability to use facts and figures to support an argument and to confront one theory with another through critical analysis.
The distinctive emphasis on critical thinking produces graduates who are intellectually flexible and open to new ideas, graduates equipped with curiosity and the capacity to adapt to ever-changing work environments, graduates who can convert recently discovered knowledge into innovative new products and services. By producing thinking and engaged leaders capable of thriving in the new age of information technology, American higher education prepares the nation for the challenges that we can’t even imagine today, challenges upon which continued growth and prosperity depends.
Conclusion
I hope that I have persuaded you that the organization of scientific research, and the pedagogical strategies used in our finest universities and colleges contribute mightily to America’s technological leadership and ultimately to national and worldwide economic growth. As China’s economy continues to grow, I would encourage you, as educated citizens of China, to hasten the wider adoption of some of the features of American higher education that I have outlined – in particular the encouragement of basic research, the decentralization of decision-making about science, and the pedagogy we employ to encourage independent, creative thinking. The tens of thousands of Chinese students who come to the U.S. to be educated every year have certainly demonstrated that they flourish in an educational system with these features.
As we strengthen and deepen the educational and cultural linkages between our countries, China will play an increasing role worldwide in extending the frontiers of science. Through expanded educational partnerships and exchanges, I am confident that you will learn well and quickly how these scientific advances can be translated effectively from the research laboratory to the creation of new and improved products. We will watch eagerly as your universities increasingly become engines of economic growth to the benefit of your people and the entire world.
